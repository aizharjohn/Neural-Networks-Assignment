{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Implementing a Feedforward Neural Network from Scratch"
      ],
      "metadata": {
        "id": "5Dw990UeZ9c8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui_rHzhhYl6k",
        "outputId": "9601b502-a50a-460b-bd5d-f580e9ce7df0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 10s - loss: 0.3689 - accuracy: 0.8942 - 10s/epoch - 5ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 9s - loss: 0.3190 - accuracy: 0.9096 - 9s/epoch - 5ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 9s - loss: 0.3043 - accuracy: 0.9144 - 9s/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 10s - loss: 0.2974 - accuracy: 0.9183 - 10s/epoch - 5ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 11s - loss: 0.2905 - accuracy: 0.9186 - 11s/epoch - 6ms/step\n",
            "313/313 - 1s - loss: 0.3225 - accuracy: 0.9105 - 835ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32251226902008057, 0.9104999899864197]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "#Loading MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "\n",
        "#Neural Network Model with single hidden layer\n",
        "inputs = keras.Input(shape=(784))\n",
        "x = layers.Dense(512, name='first_layer')(inputs)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "#Model training\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Understanding Activation Functions"
      ],
      "metadata": {
        "id": "KPlOs-mjbZiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "#Loading MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "\n",
        "#Neural Network Model with single hidden layer\n",
        "inputs = keras.Input(shape=(784))\n",
        "x = layers.Dense(512, name='first_layer', activation='relu')(inputs)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "#Model training\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6joAV9RMbgkS",
        "outputId": "398963e8-9499-437d-85c2-96e1333dba57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 10s - loss: 0.2019 - accuracy: 0.9404 - 10s/epoch - 5ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 9s - loss: 0.0819 - accuracy: 0.9753 - 9s/epoch - 5ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 9s - loss: 0.0524 - accuracy: 0.9838 - 9s/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 10s - loss: 0.0366 - accuracy: 0.9887 - 10s/epoch - 5ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 10s - loss: 0.0284 - accuracy: 0.9906 - 10s/epoch - 6ms/step\n",
            "313/313 - 1s - loss: 0.0719 - accuracy: 0.9786 - 729ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0718781054019928, 0.978600025177002]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "#Loading MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "\n",
        "#Neural Network Model with single hidden layer\n",
        "inputs = keras.Input(shape=(784))\n",
        "x = layers.Dense(512, name='first_layer', activation='sigmoid')(inputs)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "#Model training\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZvT8W4DcI3p",
        "outputId": "d4a15665-3667-4951-ad6d-7f91516b665d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 12s - loss: 0.3359 - accuracy: 0.9058 - 12s/epoch - 6ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 10s - loss: 0.1687 - accuracy: 0.9503 - 10s/epoch - 5ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 10s - loss: 0.1111 - accuracy: 0.9670 - 10s/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 11s - loss: 0.0795 - accuracy: 0.9765 - 11s/epoch - 6ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 11s - loss: 0.0583 - accuracy: 0.9821 - 11s/epoch - 6ms/step\n",
            "313/313 - 1s - loss: 0.0830 - accuracy: 0.9745 - 736ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08299736678600311, 0.9745000004768372]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "#Loading MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "\n",
        "#Neural Network Model with single hidden layer\n",
        "inputs = keras.Input(shape=(784))\n",
        "x = layers.Dense(512, name='first_layer', activation='tanh')(inputs)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "#Model training\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8mSE7ync7gj",
        "outputId": "6e2a44dd-9608-4e48-80d6-19764f59b47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 11s - loss: 0.2728 - accuracy: 0.9190 - 11s/epoch - 6ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 10s - loss: 0.1247 - accuracy: 0.9625 - 10s/epoch - 5ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 10s - loss: 0.0771 - accuracy: 0.9763 - 10s/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 10s - loss: 0.0539 - accuracy: 0.9833 - 10s/epoch - 5ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 10s - loss: 0.0372 - accuracy: 0.9886 - 10s/epoch - 5ms/step\n",
            "313/313 - 1s - loss: 0.0737 - accuracy: 0.9771 - 750ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07372621446847916, 0.9771000146865845]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Exploring Model Architecture"
      ],
      "metadata": {
        "id": "4RjyeBdKeAmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "#Loading MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
        "\n",
        "#Neural Network Model with single hidden layer\n",
        "inputs = keras.Input(shape=(784))\n",
        "x = layers.Dense(512, name='first_layer', activation='tanh')(inputs)\n",
        "x = layers.Dense(256, name='second_layer', activation='relu')(x)\n",
        "x = layers.Dense(128, name='third_layer', activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "#Model training\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OqSayCLeGgF",
        "outputId": "f0979fd1-751a-4b97-f816-0204a0d41586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 14s - loss: 0.2106 - accuracy: 0.9352 - 14s/epoch - 8ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 14s - loss: 0.1065 - accuracy: 0.9675 - 14s/epoch - 7ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 14s - loss: 0.0776 - accuracy: 0.9753 - 14s/epoch - 7ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 14s - loss: 0.0609 - accuracy: 0.9809 - 14s/epoch - 7ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 14s - loss: 0.0500 - accuracy: 0.9838 - 14s/epoch - 7ms/step\n",
            "313/313 - 1s - loss: 0.0908 - accuracy: 0.9774 - 848ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09084265679121017, 0.977400004863739]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training on Different Datasets"
      ],
      "metadata": {
        "id": "IkdCOIp5flEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "#load cifar10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "def my_model():\n",
        "  inputs = keras.Input(shape=(32, 32, 3))\n",
        "  x = layers.Conv2D(32, 3)(inputs)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.MaxPooling2D()(x)\n",
        "  x = layers.Conv2D(64, 3)(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.Conv2D(128, 3)(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "  outputs = layers.Dense(10)(x)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return model\n",
        "\n",
        "model = my_model()\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4yOTBXgfsAl",
        "outputId": "8f7a0054-e78a-45a5-f741-1217e3df8a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 - 114s - loss: 1.5769 - accuracy: 0.4294 - 114s/epoch - 146ms/step\n",
            "Epoch 2/5\n",
            "782/782 - 113s - loss: 1.2259 - accuracy: 0.5677 - 113s/epoch - 145ms/step\n",
            "Epoch 3/5\n",
            "782/782 - 113s - loss: 1.0783 - accuracy: 0.6243 - 113s/epoch - 145ms/step\n",
            "Epoch 4/5\n",
            "782/782 - 113s - loss: 0.9845 - accuracy: 0.6573 - 113s/epoch - 145ms/step\n",
            "Epoch 5/5\n",
            "782/782 - 113s - loss: 0.9082 - accuracy: 0.6842 - 113s/epoch - 145ms/step\n",
            "157/157 - 6s - loss: 0.9653 - accuracy: 0.6618 - 6s/epoch - 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9652830362319946, 0.6618000268936157]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Regularization Techniques"
      ],
      "metadata": {
        "id": "ndYlMdAZj789"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "#load cifar10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "def my_model():\n",
        "  inputs = keras.Input(shape=(32, 32, 3))\n",
        "  x = layers.Conv2D(32, 3, padding='same', kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.MaxPooling2D()(x)\n",
        "  x = layers.Conv2D(64, 3, padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(64, kernel_regularizer=regularizers.l2(0.01), activation='relu')(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  outputs = layers.Dense(10)(x)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return model\n",
        "\n",
        "model = my_model()\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9g-92xRkAA3",
        "outputId": "c6ddeda3-c83d-442e-9b8a-3e36cf021570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 - 242s - loss: 3.0227 - accuracy: 0.1883 - 242s/epoch - 310ms/step\n",
            "Epoch 2/5\n",
            "782/782 - 243s - loss: 2.2135 - accuracy: 0.1959 - 243s/epoch - 311ms/step\n",
            "Epoch 3/5\n",
            "782/782 - 242s - loss: 2.1047 - accuracy: 0.1996 - 242s/epoch - 309ms/step\n",
            "Epoch 4/5\n",
            "782/782 - 243s - loss: 2.0635 - accuracy: 0.2042 - 243s/epoch - 310ms/step\n",
            "Epoch 5/5\n",
            "782/782 - 251s - loss: 2.0220 - accuracy: 0.2262 - 251s/epoch - 321ms/step\n",
            "157/157 - 13s - loss: 1.7437 - accuracy: 0.3666 - 13s/epoch - 86ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7437465190887451, 0.36660000681877136]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "5EbpiVefsc1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import kerastuner\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "#Loading MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Flatten(input_shape = (28,28)))\n",
        "  model.add(layers.Dense(units=hp.Int('first layer units', min_value=32, max_value=512, step=128),\n",
        "                         name='first_layer',\n",
        "                         activation='relu'))\n",
        "  model.add(layers.Dense(units=hp.Int('second layer units', min_value=32, max_value=256, step=128),\n",
        "                         name='second_layer',\n",
        "                         activation='relu'))\n",
        "  model.add(layers.Dense(units=hp.Int('third layer units', min_value=32, max_value=128, step=64),\n",
        "                         name='third_layer',\n",
        "                         activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-4])),\n",
        "    metrics=[\"accuracy\"]\n",
        "  )\n",
        "  return model\n",
        "\n",
        "tuner = kerastuner.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=4,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dir',\n",
        "    project_name='hyperparameter'\n",
        "    )\n",
        "\n",
        "#tuner.space_search_summary()\n",
        "\n",
        "#Model training\n",
        "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "tuner.results_summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxpkRCngsu8R",
        "outputId": "702012e6-5ffd-4117-be42-055cbad2982d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 4 Complete [00h 05m 26s]\n",
            "val_accuracy: 0.9632999897003174\n",
            "\n",
            "Best val_accuracy So Far: 0.9632999897003174\n",
            "Total elapsed time: 00h 12m 01s\n",
            "Results summary\n",
            "Results in my_dir/hyperparameter\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 3 summary\n",
            "Hyperparameters:\n",
            "first layer units: 416\n",
            "second layer units: 32\n",
            "third layer units: 32\n",
            "learning_rate: 0.01\n",
            "Score: 0.9632999897003174\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "first layer units: 160\n",
            "second layer units: 32\n",
            "third layer units: 32\n",
            "learning_rate: 0.0001\n",
            "Score: 0.9618333379427592\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "first layer units: 32\n",
            "second layer units: 32\n",
            "third layer units: 96\n",
            "learning_rate: 0.0001\n",
            "Score: 0.9435666799545288\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "first layer units: 32\n",
            "second layer units: 32\n",
            "third layer units: 32\n",
            "learning_rate: 0.0001\n",
            "Score: 0.9370333353678385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/keras-team/keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3Yrfjvkw3nJ",
        "outputId": "6bba6eca-5687-400c-8f4d-1d5dcea63f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'keras-tuner'...\n",
            "remote: Enumerating objects: 9259, done.\u001b[K\n",
            "remote: Counting objects: 100% (766/766), done.\u001b[K\n",
            "remote: Compressing objects: 100% (306/306), done.\u001b[K\n",
            "remote: Total 9259 (delta 580), reused 550 (delta 460), pack-reused 8493\u001b[K\n",
            "Receiving objects: 100% (9259/9259), 2.18 MiB | 9.53 MiB/s, done.\n",
            "Resolving deltas: 100% (6600/6600), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WW8ldpXw7j8",
        "outputId": "c049f5c4-6400-430e-8738-dded85f64632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    }
  ]
}